[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "My name is Maeve Horan-Portelance, and I am a fourth-year undergraduate student at UCLA, majoring in Statistics and Data Science with minors in Global Health and Film, Television, and Digital Media.\nI am interested in data analytics across multiple disciplines, including healthcare, business intelligence, and media analytics. My background combines quantitative problem-solving with creative storytelling, allowing me to analyze complex data while communicating meaningful insights.\nI have experience in data analysis, regression modeling, machine learning, data visualization, and database management. My technical skills include R, Python, C++, SQL, Snowflake, Tableau, and MicroStrategy. Additionally, my background in creative writing, dance, and jazz drumming gives me a unique approach to problem-solving.\nOutside of school and work, I enjoy dancingâ€“after 15 years of competitive dance, I joined UCLAâ€™s Icarus Contemporary Dance Company, for which I currently serve as Finance Director (June 2023 - present), as well as choreograph and perform. I also enjoy playing the piano and drums, running, hiking, and exploring LA!"
  },
  {
    "objectID": "about.html#relevant-coursework",
    "href": "about.html#relevant-coursework",
    "title": "About Me",
    "section": "Relevant Coursework",
    "text": "Relevant Coursework\n\nStats 20: Introduction to Statistical Programming with R\n\nStats 100A: Introduction to Probability\n\nStats 100B: Introduction to Mathematical Statistics\nStats 100C: Linear Models\n\nStats 101A: Introduction to Data Analysis and Regression\n\nStats 101B: Introduction to Design and Analysis of Experiments\nStats 101C: Introduction to Statistical Models and Data Mining\nStats 102A: Introduction to Computational Statistics with R\nStats 102B: Introduction to Computation and Optimization\nStats 102C: Monte Carlo Methods\n\nStats C116: Social Statistics (Bayesian Analysis)\n\nStats 112: Statistics: Window for Understanding Diversity"
  },
  {
    "objectID": "about.html#additional-interests",
    "href": "about.html#additional-interests",
    "title": "About Me",
    "section": "Additional Interests",
    "text": "Additional Interests\n\nContemporary and jazz dance and choreography\nPlaying piano and jazz drums\nScreenwriting, storytelling, and other forms of creative writing\nRunning and hiking"
  },
  {
    "objectID": "Projects.html",
    "href": "Projects.html",
    "title": "Projects",
    "section": "",
    "text": "Bayesian Logistic Regression\n\n\nA comparison of Bayesian and Frequentist logistic regression models using diabetes prediction data.\n\n\n\nMaeve Horan-Portelance\n\n\nJun 14, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nHigh School Academic Performance Analysis\n\n\nA multinomial logistic regression analysis of the relationship between demographics, study habits, and high school GPA.\n\n\n\nMaeve Horan-Portelance, Debanshi Misra, Anika Chowdhury, Angelo Desiderio, Ashley Chan\n\n\nDec 1, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting Alcoholic Status Using Vitals\n\n\nUsing machine learning to predict alcoholic status based on vital health statistics.\n\n\n\nMaeve Horan-Portelance, John Wu, Justin Noche, Kanchan Raju, Shashvat Patel\n\n\nDec 17, 2023\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "Projects/Academic_Performance.html",
    "href": "Projects/Academic_Performance.html",
    "title": "High School Academic Performance Analysis",
    "section": "",
    "text": "This project explores how demographic, familial, and behavioral factors influence high school student academic performance. Using a dataset sourced from Kaggle, we analyzed predictors such as age, gender, parental education, study habits, extracurricular involvement, and absences to determine their impact on GPA.\nThe primary objective was to train and evaluate a multinomial logistic regression model to classify students into three GPA categories:\n- Low GPA: (&lt; 2.5)\n- Medium GPA: (2.5 - 3.0)\n- High GPA: (&gt; 3.0)\nOur analysis included feature selection, model validation, and cross-validation to improve predictive performance.\nðŸ“„ Download Full Report (PDF)"
  },
  {
    "objectID": "Projects/Academic_Performance.html#dataset-and-feature-engineering.",
    "href": "Projects/Academic_Performance.html#dataset-and-feature-engineering.",
    "title": "High School Academic Performance Analysis",
    "section": "Dataset and Feature Engineering.",
    "text": "Dataset and Feature Engineering.\n\nThe dataset consists of high school student profiles, including demographic, academic, and extracurricular data.\n\nWe removed highly correlated variables using Variance Inflation Factor (VIF) analysis.\n\nThe final model included the following predictors:\n\nBehavioral factors: Study time, absences, tutoring, and extracurricular activities.\nDemographic factors: Age, gender, ethnicity, and parental education."
  },
  {
    "objectID": "Projects/Academic_Performance.html#exploratory-data-analysis-eda",
    "href": "Projects/Academic_Performance.html#exploratory-data-analysis-eda",
    "title": "High School Academic Performance Analysis",
    "section": "Exploratory Data Analysis (EDA)",
    "text": "Exploratory Data Analysis (EDA)\n\nVisualized GPA distribution across age groups, gender, and ethnicity.\nExamined correlations between study habits, parental involvement, and GPA.\nBoxplots and scatterplots were used to assess trends in study time and absenteeism."
  },
  {
    "objectID": "Projects/Academic_Performance.html#multinomial-logistic-regression-model",
    "href": "Projects/Academic_Performance.html#multinomial-logistic-regression-model",
    "title": "High School Academic Performance Analysis",
    "section": "Multinomial Logistic Regression Model",
    "text": "Multinomial Logistic Regression Model\n\nImplemented multinomial logistic regression to classify GPA into three categories.\nOdds ratios were calculated to interpret predictor significance.\nCross-validation (10-fold and LOOCV) was used to validate model performance.\nCompared results using Random Forest variable importance analysis."
  },
  {
    "objectID": "Projects/Alcohol.html",
    "href": "Projects/Alcohol.html",
    "title": "Predicting Alcoholic Status Using Vitals",
    "section": "",
    "text": "This project aims to develop a machine learning model to predict whether an individual is an alcoholic or non-alcoholic based on vital health statistics. The dataset, collected by the National Health Insurance Service in Korea, contains 26 predictor variables, including age, weight, hemoglobin levels, smoking status, and more.\nWe implemented several classification models and feature selection techniques to improve predictive performance. Our best model, an XGBoost classifier with Hmisc imputation, achieved a Kaggle score of 0.7315, in the top 20 on the class leaderboard.\nðŸ“„ Download Full Report (PDF)"
  },
  {
    "objectID": "Projects/Alcohol.html#dataset-and-preprocessing",
    "href": "Projects/Alcohol.html#dataset-and-preprocessing",
    "title": "Predicting Alcoholic Status Using Vitals",
    "section": "Dataset and Preprocessing",
    "text": "Dataset and Preprocessing\n\nData sourced from the National Health Insurance Service in Korea.\nFeatures include demographic, behavioral, and biological markers.\nApplied missing value imputation due to ~7% missing values in most predictors.\nConducted Exploratory Data Analysis (EDA) using ggplot2 in R."
  },
  {
    "objectID": "Projects/Alcohol.html#missing-value-imputation",
    "href": "Projects/Alcohol.html#missing-value-imputation",
    "title": "Predicting Alcoholic Status Using Vitals",
    "section": "Missing Value Imputation",
    "text": "Missing Value Imputation\nWe tested three different missing data imputation techniques:\n- MICE (Multivariate Imputation by Chained Equations)\n- Hmisc (Harrell Miscellaneous) imputation\n- Amelia imputation (multiple imputation assuming normality)\nFinal imputed dataset was selected based on cross-validation accuracy."
  },
  {
    "objectID": "Projects/Alcohol.html#model-selection",
    "href": "Projects/Alcohol.html#model-selection",
    "title": "Predicting Alcoholic Status Using Vitals",
    "section": "Model Selection",
    "text": "Model Selection\nWe tested multiple models to find the best-performing classifier:\n- Random Forest: Kaggle Score 0.7294\n- Logistic Regression: Kaggle Score 0.7236\n- XGBoost (Final Model): Kaggle Score 0.7315 (Best Performing Model)\nWe optimized the XGBoost model using:\n- Gradient boosting techniques\n- Feature importance scoring\n- Hyperparameter tuning (learning rate, max depth, and tree count)"
  },
  {
    "objectID": "Projects/Bayesian.html",
    "href": "Projects/Bayesian.html",
    "title": "Bayesian Logistic Regression",
    "section": "",
    "text": "This project explores the Bayesian approach to logistic regression, focusing on its theoretical foundations, practical applications, and comparison to frequentist methods. The analysis uses data from the National Institute of Diabetes, which predicts the onset of diabetes in Pima Indians based on diagnostic measures such as BMI, glucose levels, blood pressure, insulin levels, and family history.\nWe tested four key research questions: 1. Performance comparison between Bayesian and frequentist logistic models. 2. Accuracy assessment of MICE vs.Â BRMS imputation for missing values. 3. Impact of prior selection (Horseshoe vs.Â Laplace) on Bayesian regression. 4. Effect of adding interaction terms on predictive performance.\nðŸ“„ Download Full Report (PDF)"
  },
  {
    "objectID": "Projects/Bayesian.html#frequentist-approach",
    "href": "Projects/Bayesian.html#frequentist-approach",
    "title": "Bayesian Logistic Regression",
    "section": "Frequentist Approach",
    "text": "Frequentist Approach\n\nUsed Generalized Linear Models (GLM) for logistic regression.\nHandled missing data using MICE (Multiple Imputation by Chained Equations).\nEvaluated model accuracy using confusion matrices, precision, recall, and AUC scores."
  },
  {
    "objectID": "Projects/Bayesian.html#bayesian-approach",
    "href": "Projects/Bayesian.html#bayesian-approach",
    "title": "Bayesian Logistic Regression",
    "section": "Bayesian Approach",
    "text": "Bayesian Approach\n\nImplemented Bayesian logistic regression using the brms package in R.\nImputed missing data using both MICE and BRMS-native imputation.\nExplored the impact of different sparsity priors:\n\nHorseshoe Prior: Encourages sparsity and shrinks unimportant coefficients.\nLaplace Prior: Applies uniform shrinkage to coefficients.\n\nUsed Markov Chain Monte Carlo (MCMC) sampling for posterior estimation.\nCompared model performance using posterior distributions, trace plots, and WAIC/AUC scores."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Maeve Horan-Portelance",
    "section": "",
    "text": "Maeve Horan-Portelance is an undergraduate student at UCLA studying Statistics and Data Science with minors in Global Health and Film, TV and Digital Media. She has a strong interest in data analytics and enjoys combining her quantitative skills and creative abilities to solve complex problems.\nShe has both work and educational experience in data analysis, experimental design, data mining, statistical modeling, and machine learning. She is proficient in R, Python, C++, SQL, Tableau and MicroStrategy.\nDownload my resume."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Maeve Horan-Portelance",
    "section": "Education",
    "text": "Education\nUniversity of California, Los Angeles (UCLA)\nLos Angeles, CA\nBachelor of Science in Statistics and Data Science\nMinors: Global Health; Film, TV and Digital Media\nSeptember 2021 â€“ June 2025\nGPA: 3.99"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Maeve Horan-Portelance",
    "section": "Experience",
    "text": "Experience\nUCLA College Academic Counseling | Los Angeles, CA\nLead Undergraduate Data Analyst and Peer Counselor\nSeptember 2023 â€“ Present\nTravelers Insurance | Hartford, CT\nDecision Science Intern | Business Insights & Analytics LDP\nJune 2024 â€“ August 2024\nIBM Accelerate | Remote\nProgram Participant | Client Engineering and Technical Sales June 2023 â€“ August 2023\nDavid Geffen School of Medicine | Los Angeles, CA\nUndergraduate Research Intern | Biomedical Informatics\nOctober 2022 â€“ October 2023\nPioneer Financial Group | Windsor, CT\nAnalytics Intern\nJune 2022 â€“ September 2022"
  }
]